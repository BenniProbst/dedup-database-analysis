# COMDARE Multi-Platform CI/CD Template v5.3.0 (BS-3040)
# v5.3.0: aggregate+upload via rules:when:always + stage-ordering, 10min timeout on K8s
# v5.2.0: Unique build dirs + coverage per BM OS, corrected artifact handling
# v5.1.0: Split BM into Debian + Ubuntu (incompatible OS, separate runner pools)
# v5.0.0: ALL build jobs in single stage (parallel execution)
#
# === Runner Architecture (12 total, 10 online, 2 paused) ===
# Parallelization: 7 independent execution lanes in single build stage
#
# Lane 1: K8s (Docker)        — kubernetes tag — pve1/node3/node4 Talos VMs
# Lane 2: BM-Debian (Shell)   — debian+x86_64  — pve1 (pve2 paused/experiment)
# Lane 3: BM-Ubuntu (Shell)   — ubuntu+x86_64  — node3, node4
# Lane 4: macOS x86 (Shell)   — macos+x86_64   — node5 (independent)
# Lane 5: macOS ARM (Shell)   — macos+arm64    — node6 (independent)
# Lane 6: Linux ARM64 (Shell) — arm64+linux    — node7 (independent)
# Lane 7: Linux RISC-V (Shell)— riscv64+linux  — node8 (independent)
#
# XOR: K8s runner XOR BM runner per physical host (pve1/pve2/node3/node4)
# Exotic nodes (5-8) have no XOR constraint — fully independent
# Phase 1: K8s + BM = MANDATORY, Exotic = allow_failure

stages:
  - build
  - aggregate
  - upload
  - experiment-build
  - experiment-preflight
  - experiment-run
  - experiment-cleanup

variables:
  GCC_VERSION: "14"
  BUILD_TYPE: "Debug"

# ============================================================
# Stage 1: ALL Builds (7 parallel execution lanes)
# ============================================================

# --- Lane 1: K8s Build (Docker executor, MANDATORY) ---
build-k8s:
  stage: build
  timeout: 10 minutes
  image: gcc:${GCC_VERSION}
  tags:
    - kubernetes
  before_script:
    - '(while true; do sleep 25; echo "[keepalive $(date -u +%H:%M:%S)]"; done) &'
    - KEEPALIVE_PID=$!
    - apt-get update -qq && apt-get install -y -qq cmake ninja-build git python3-pip >/dev/null 2>&1
    - pip install gcovr --break-system-packages -q
    - git config --global url."http://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-webservice-default.gitlab.svc:8181/".insteadOf "https://gitlab.comdare.de/"
  script:
    - echo "=== COMDARE CI v5.3 — K8s (gcc:${GCC_VERSION}, x86_64) ==="
    - test -f CMakeLists.txt || { echo "No CMakeLists.txt — skipping"; kill $KEEPALIVE_PID 2>/dev/null || true; exit 0; }
    - cmake -B build-k8s -G Ninja -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DBUILD_TESTS=ON -DCMAKE_CXX_FLAGS="--coverage -std=c++23" -DCMAKE_C_FLAGS=--coverage -DCMAKE_EXE_LINKER_FLAGS=--coverage
    - cmake --build build-k8s -j $(nproc)
    - cd build-k8s && ctest --output-on-failure -j$(nproc) || true
    - cd $CI_PROJECT_DIR
    - kill $KEEPALIVE_PID 2>/dev/null || true
    - sleep 1
    - gcovr --root . --filter 'include/' --filter 'src/' --exclude 'build-k8s/_deps' --print-summary --xml coverage-k8s.xml || true
  coverage: '/lines:\s+(\d+\.\d+)%/'
  artifacts:
    paths:
      - coverage-k8s.xml
      - build-k8s/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage-k8s.xml
    expire_in: 30 days
    when: always

# --- Lane 2: Debian x86_64 (pve1, pve2) — MANDATORY ---
build-debian-x86:
  stage: build
  tags:
    - debian
    - x86_64
  before_script:
    - 'echo "=== COMDARE CI v5.3 — Debian x86_64 ($(uname -m)) ==="'
    - 'command -v git >/dev/null || { echo "ERROR: git not found. Run BS-3049 bootstrap."; exit 1; }'
    - 'command -v cmake >/dev/null || { echo "ERROR: cmake not found. Run BS-3049 bootstrap."; exit 1; }'
    - 'command -v gcc >/dev/null || { echo "ERROR: gcc not found. Run BS-3049 bootstrap."; exit 1; }'
    - 'echo "Toolchain: gcc $(gcc -dumpversion 2>/dev/null), cmake $(cmake --version 2>/dev/null | head -1)"'
  script:
    - test -f CMakeLists.txt || { echo "No CMakeLists.txt — skipping"; exit 0; }
    - cmake -B build-debian -G Ninja -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DBUILD_TESTS=ON -DCMAKE_CXX_FLAGS="--coverage -std=c++23" -DCMAKE_C_FLAGS=--coverage -DCMAKE_EXE_LINKER_FLAGS=--coverage
    - cmake --build build-debian -j $(nproc)
    - cd build-debian && ctest --output-on-failure -j$(nproc) || true
    - cd $CI_PROJECT_DIR
    - 'command -v gcovr >/dev/null && gcovr --root . --filter include/ --filter src/ --exclude build-debian/_deps --print-summary --xml coverage-debian.xml || echo "gcovr not found — skipping coverage"'
  coverage: '/lines:\s+(\d+\.\d+)%/'
  artifacts:
    paths:
      - coverage-debian.xml
      - build-debian/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage-debian.xml
    expire_in: 30 days
    when: always

# --- Lane 3: Ubuntu x86_64 (node3, node4) — MANDATORY ---
build-ubuntu-x86:
  stage: build
  tags:
    - ubuntu
    - x86_64
  before_script:
    - 'echo "=== COMDARE CI v5.3 — Ubuntu x86_64 ($(uname -m)) ==="'
    - 'command -v git >/dev/null || { echo "ERROR: git not found. Run BS-3049 bootstrap."; exit 1; }'
    - 'command -v cmake >/dev/null || { echo "ERROR: cmake not found. Run BS-3049 bootstrap."; exit 1; }'
    - 'command -v gcc >/dev/null || { echo "ERROR: gcc not found. Run BS-3049 bootstrap."; exit 1; }'
    - 'echo "Toolchain: gcc $(gcc -dumpversion 2>/dev/null), cmake $(cmake --version 2>/dev/null | head -1)"'
  script:
    - test -f CMakeLists.txt || { echo "No CMakeLists.txt — skipping"; exit 0; }
    - cmake -B build-ubuntu -G Ninja -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DBUILD_TESTS=ON -DCMAKE_CXX_FLAGS="--coverage -std=c++23" -DCMAKE_C_FLAGS=--coverage -DCMAKE_EXE_LINKER_FLAGS=--coverage
    - cmake --build build-ubuntu -j $(nproc)
    - cd build-ubuntu && ctest --output-on-failure -j$(nproc) || true
    - cd $CI_PROJECT_DIR
    - 'command -v gcovr >/dev/null && gcovr --root . --filter include/ --filter src/ --exclude build-ubuntu/_deps --print-summary --xml coverage-ubuntu.xml || echo "gcovr not found — skipping coverage"'
  coverage: '/lines:\s+(\d+\.\d+)%/'
  artifacts:
    paths:
      - coverage-ubuntu.xml
      - build-ubuntu/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage-ubuntu.xml
    expire_in: 30 days
    when: always

# --- Lanes 4-7: Exotic Platforms (Shell executor, SOFT-FAIL Phase 1) ---
.exotic-base:
  stage: build
  allow_failure: true
  before_script:
    - 'echo "=== COMDARE CI v5.3 — Exotic ($(uname -s) $(uname -m)) ==="'
    - 'command -v git >/dev/null || { echo "WARN: git not found — skipping"; exit 0; }'
    - 'command -v cmake >/dev/null || { echo "WARN: cmake not found — skipping"; exit 0; }'
  script:
    - test -f CMakeLists.txt || { echo "No CMakeLists.txt — skipping"; exit 0; }
    - 'GEN=""; command -v ninja >/dev/null && GEN="-G Ninja"'
    - cmake -B build-exotic $GEN -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DBUILD_TESTS=ON -DCMAKE_CXX_STANDARD=23
    - cmake --build build-exotic -j $(nproc 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo 2)
    - cd build-exotic && ctest --output-on-failure || true
    - cd $CI_PROJECT_DIR
  artifacts:
    paths:
      - build-exotic/
    expire_in: 30 days
    when: always

# Lane 4: macOS x86_64 (node5)
build-macos-x86:
  extends: .exotic-base
  tags:
    - macos
    - x86_64

# Lane 5: macOS ARM64 (node6)
build-macos-arm:
  extends: .exotic-base
  tags:
    - macos
    - arm64

# Lane 6: Linux ARM64 (node7)
build-linux-arm64:
  extends: .exotic-base
  tags:
    - arm64
    - linux

# Lane 7: Linux RISC-V (node8)
build-linux-riscv:
  extends: .exotic-base
  tags:
    - riscv64
    - linux

# ============================================================
# Stage 2: Aggregate Results
# ============================================================
aggregate-results:
  stage: aggregate
  image: alpine:latest
  tags:
    - kubernetes
  rules:
    - when: always
  script:
    - echo "=== COMDARE CI v5.3 — Aggregate Results ==="
    - echo "Platform build results:"
    - '[ -f coverage-k8s.xml ] && echo "  K8s Docker (x86_64):  OK" || echo "  K8s Docker (x86_64):  MISSING"'
    - '[ -f coverage-debian.xml ] && echo "  Debian BM (x86_64):   OK" || echo "  Debian BM (x86_64):   MISSING"'
    - '[ -f coverage-ubuntu.xml ] && echo "  Ubuntu BM (x86_64):   OK" || echo "  Ubuntu BM (x86_64):   MISSING"'
    - '[ -d build-exotic ] && echo "  Exotic platforms:      artifacts present" || echo "  Exotic platforms:      no artifacts"'
    - echo "Pipeline $CI_PIPELINE_ID complete on $(date -u)"
  artifacts:
    paths:
      - coverage-k8s.xml
      - coverage-debian.xml
      - coverage-ubuntu.xml
    expire_in: 30 days
    when: always

# ============================================================
# Stage 3: Upload Artifacts to MinIO (buildsystem-artifacts)
# RBMM Path Hierarchy: {project}/{platform}/{arch}/{runner_class}/{pipeline_id}/
# ============================================================
upload-to-minio:
  stage: upload
  image: alpine:latest
  tags:
    - kubernetes
  script:
    - apk add --no-cache curl >/dev/null 2>&1
    - curl -sSL https://dl.min.io/client/mc/release/linux-amd64/mc -o /usr/local/bin/mc
    - chmod +x /usr/local/bin/mc
    - mc alias set ci $MINIO_ENDPOINT $MINIO_ACCESS_KEY $MINIO_SECRET_KEY --api S3v4
    - export B="buildsystem-artifacts/${CI_PROJECT_PATH}"
    - export P="${CI_PIPELINE_ID}"
    - echo "=== COMDARE CI v5.3 — MinIO Artifact Upload ==="
    - echo "RBMM Hierarchy — {project}/{platform}/{arch}/{runner_class}/{pipeline_id}/"
    - test -f coverage-k8s.xml && mc cp coverage-k8s.xml ci/${B}/linux/x86_64/k8s/${P}/coverage/ && echo "  OK linux/x86_64/k8s" || true
    - test -f coverage-debian.xml && mc cp coverage-debian.xml ci/${B}/linux/x86_64/debian/${P}/coverage/ && echo "  OK linux/x86_64/debian" || true
    - test -f coverage-ubuntu.xml && mc cp coverage-ubuntu.xml ci/${B}/linux/x86_64/ubuntu/${P}/coverage/ && echo "  OK linux/x86_64/ubuntu" || true
    - echo "--- Upload Summary ---"
    - mc ls ci/${B}/ --recursive || true
    - echo "Upload complete for pipeline ${P}"
  allow_failure: true
  rules:
    - if: '$MINIO_ENDPOINT && $MINIO_ACCESS_KEY && $MINIO_SECRET_KEY'
      when: always
    - when: never

# =============================================================================
# PIPELINE 2: Real DB Experiment (sequential per-DB, 3 repetitions each)
# =============================================================================
# Runner: k8s-runner-4 (ID 17) on dedicated node talos-say-ls6
#   - Tag: "experiment" (only tag, run_untagged=false)
#   - Node selector: kubernetes.io/hostname=talos-say-ls6
#   - Toleration: experiment=dedicated:NoSchedule
# Safety: Samba AD lab user (dedup-lab), isolated lab schemas, cleanup guaranteed
# =============================================================================

.experiment-default: &experiment-default
  image: gcc:14-bookworm
  tags:
    - experiment
  before_script:
    - |
      apt-get update -qq > /dev/null 2>&1
      apt-get install -y -qq --no-install-recommends \
        libpq-dev libhiredis-dev librdkafka-dev libcurl4-openssl-dev \
        libmariadb-dev nlohmann-json3-dev cmake ninja-build nfs-common \
        > /dev/null 2>&1
      echo "Build-tools ready: GCC $(gcc -dumpversion) + CMake + Ninja"

experiment:build:
  <<: *experiment-default
  stage: experiment-build
  needs: []
  script:
    - |
      echo "=== Experiment Build: dedup-test v${CI_COMMIT_SHORT_SHA} ==="
      mkdir -p build && cd build
      cmake ../src/cpp -DCMAKE_BUILD_TYPE=Release
      make -j4 dedup-test 2>&1
      echo "=== Binary ready ==="
      ls -lh dedup-test
      file dedup-test
  artifacts:
    paths:
      - build/dedup-test
    expire_in: 7 days
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "api"
    - if: $CI_PIPELINE_SOURCE == "push"
      changes:
        - "src/cpp/**/*.cpp"
        - "src/cpp/**/*.hpp"
        - "src/cpp/**/*.h"
        - "src/cpp/CMakeLists.txt"
        - ".gitlab-ci.yml"

experiment:preflight:
  tags:
    - experiment
  image: gcc:14-bookworm
  stage: experiment-preflight
  needs: ["experiment:build"]
  timeout: 5 minutes
  retry:
    max: 2
    when: [runner_system_failure, script_failure]
  script:
    - |
      apt-get update -qq > /dev/null 2>&1
      apt-get install -y -qq --no-install-recommends \
        postgresql-client default-mysql-client redis-tools curl netcat-openbsd \
        > /dev/null 2>&1
      echo "=== Pre-Flight: Checking all 7 DB systems ==="
      PASS=0; FAIL=0
      check() {
        if eval "$2" > /dev/null 2>&1; then
          echo "  OK  $1"; PASS=$((PASS+1))
        else
          echo "  FAIL $1"; FAIL=$((FAIL+1))
        fi
      }
      check "PostgreSQL"   "pg_isready -h postgres-lb.databases.svc.cluster.local -p 5432 -t 5"
      check "CockroachDB"  "pg_isready -h cockroachdb-public.cockroach-operator-system.svc.cluster.local -p 26257 -t 5"
      check "MariaDB"      "mysqladmin ping -h mariadb.databases.svc.cluster.local -P 3306 --connect-timeout=5"
      check "ClickHouse"   "curl -sf --max-time 5 'http://clickhouse.databases.svc.cluster.local:8123/ping'"
      check "Redis"        "redis-cli -h redis-cluster.redis.svc.cluster.local -p 6379 ping"
      check "Kafka"        "nc -z -w5 kafka-cluster-kafka-bootstrap.kafka.svc.cluster.local 9092"
      check "MinIO"        "curl -sf --max-time 5 'http://minio-lb.minio.svc.cluster.local:9000/minio/health/live'"
      echo "=== Result: ${PASS}/7 passed, ${FAIL}/7 failed ==="
      [ "$FAIL" -eq 0 ] || exit 1
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "api"
    - if: $CI_PIPELINE_SOURCE == "push"
      changes:
        - "src/cpp/**/*.cpp"
        - "src/cpp/**/*.hpp"
        - "src/cpp/**/*.h"
        - "src/cpp/CMakeLists.txt"
        - ".gitlab-ci.yml"

.experiment-per-db: &experiment-per-db
  <<: *experiment-default
  stage: experiment-run
  timeout: 6 hours
  retry:
    max: 1
    when: [runner_system_failure]
  script:
    - |
      echo "================================================================="
      echo "  EXPERIMENT: ${DB_SYSTEM} (3 repetitions)"
      echo "  Lab user: dedup-lab | Lab schema: dedup_lab"
      echo "  Payload types: ${PAYLOAD_TYPES}"
      echo "  Resume: checkpoint-dir + per-run-id tracking"
      echo "================================================================="

      # Try NFS mount for real-world datasets
      mkdir -p /datasets/real-world
      mount -t nfs4 10.0.110.184:/ /datasets/real-world 2>/dev/null && echo "[NFS] Mounted real-world datasets" || echo "[NFS] WARNING: Cannot mount 10.0.110.184 — NAS payload types will be skipped"

      chmod +x build/dedup-test
      OVERALL_EXIT=0

      for RUN in 1 2 3; do
        echo ""
        echo "===== ${DB_SYSTEM}: Attempt ${RUN}/3 ====="
        echo ""
        SEED=$((42 + RUN))
        mkdir -p results/${DB_SYSTEM}/run-${RUN}

        echo "===== Run ${RUN}/3 (seed=${SEED}) ====="

        build/dedup-test \
          --config src/cpp/config.example.json \
          --systems "${DB_SYSTEM}" \
          --generate-data \
          --data-dir /tmp/datasets \
          --results-dir "results/${DB_SYSTEM}/run-${RUN}" \
          --num-files 500 \
          --file-size 524288 \
          --seed ${SEED} \
          --checkpoint-dir "results/${DB_SYSTEM}/checkpoints" \
          --run-id ${RUN} \
          --max-retries 3 \
          --verbose 2>&1 || {
            echo "WARNING: Run ${RUN} exited with code $?"
            OVERALL_EXIT=1
          }

        echo "===== Run ${RUN}/3 complete ====="
        ls -la results/${DB_SYSTEM}/run-${RUN}/ 2>/dev/null || true
      done

      echo ""
      echo "=== All 3 runs complete for ${DB_SYSTEM} ==="
      echo "=== Overall exit: ${OVERALL_EXIT} ==="

      # Export combined results
      if ls results/${DB_SYSTEM}/run-*/combined_results.json 2>/dev/null; then
        echo "Results files found"
      fi

      umount /datasets/real-world 2>/dev/null || true
      exit ${OVERALL_EXIT}
  after_script:
    - |
      echo "=== Cleanup: dropping lab schemas ==="
      # Lab schema cleanup is handled by the binary's --cleanup flag
      # but we ensure NFS unmount here
      umount /datasets/real-world 2>/dev/null || true
  artifacts:
    paths:
      - results/
    expire_in: 365 days
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "api"
    - if: $CI_PIPELINE_SOURCE == "push"
      changes:
        - "src/cpp/**/*.cpp"
        - "src/cpp/**/*.hpp"
        - "src/cpp/**/*.h"
        - "src/cpp/CMakeLists.txt"
        - ".gitlab-ci.yml"

experiment:postgresql:
  <<: *experiment-per-db
  needs: ["experiment:preflight", "experiment:build"]
  variables:
    DB_SYSTEM: "postgresql"
    PAYLOAD_TYPES: "random_binary,structured_json,text_document,uuid_keys,jsonb_documents,bank_transactions,text_corpus,numeric_dataset"

experiment:cockroachdb:
  <<: *experiment-per-db
  needs: ["experiment:postgresql", "experiment:build"]
  variables:
    DB_SYSTEM: "cockroachdb"
    PAYLOAD_TYPES: "random_binary,structured_json,text_document,uuid_keys,jsonb_documents,bank_transactions,text_corpus,numeric_dataset"

experiment:mariadb:
  <<: *experiment-per-db
  needs: ["experiment:cockroachdb", "experiment:build"]
  variables:
    DB_SYSTEM: "mariadb"
    PAYLOAD_TYPES: "random_binary,structured_json,text_document,uuid_keys,jsonb_documents,bank_transactions,text_corpus,numeric_dataset"

experiment:clickhouse:
  <<: *experiment-per-db
  needs: ["experiment:mariadb", "experiment:build"]
  variables:
    DB_SYSTEM: "clickhouse"
    PAYLOAD_TYPES: "random_binary,structured_json,text_document,uuid_keys,jsonb_documents,bank_transactions,text_corpus,numeric_dataset"

experiment:redis:
  <<: *experiment-per-db
  needs: ["experiment:clickhouse", "experiment:build"]
  variables:
    DB_SYSTEM: "redis"
    PAYLOAD_TYPES: "random_binary,structured_json,text_document,uuid_keys,jsonb_documents"

experiment:kafka:
  <<: *experiment-per-db
  needs: ["experiment:redis", "experiment:build"]
  variables:
    DB_SYSTEM: "kafka"
    PAYLOAD_TYPES: "random_binary,structured_json,text_document,uuid_keys,jsonb_documents"

experiment:minio:
  <<: *experiment-per-db
  needs: ["experiment:kafka", "experiment:build"]
  variables:
    DB_SYSTEM: "minio"
    PAYLOAD_TYPES: "random_binary,structured_json,text_document,uuid_keys,jsonb_documents"

experiment:run-all:
  stage: experiment-run
  tags:
    - experiment
  image: alpine:latest
  when: manual
  needs: ["experiment:build"]
  script:
    - echo "Manual trigger for full experiment cascade"
    - echo "Use individual DB jobs instead (they chain automatically)"
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "api"
      when: manual

experiment:cleanup:
  stage: experiment-cleanup
  tags:
    - experiment
  image: alpine:latest
  when: manual
  needs: []
  script:
    - echo "=== Post-Experiment Cleanup ==="
    - echo "Manual cleanup — verify results before running"
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "api"
      when: manual
